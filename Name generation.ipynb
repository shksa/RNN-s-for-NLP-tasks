{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Japanese', 'Czech', 'Greek', 'Irish', 'French', 'English', 'Chinese', 'Polish', 'Portuguese', 'Italian', 'Scottish', 'Vietnamese', 'Dutch', 'Arabic', 'Spanish', 'German', 'Russian', 'Korean']\n",
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from dataUtils import *\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_inputChar, dim_hiddenState, dim_output, dim_catagory = 18):\n",
    "        super(GenRNN, self).__init__()\n",
    "        self.hiddenStateDim = dim_hiddenState\n",
    "        self.i2h = nn.Linear(dim_catagory + dim_inputChar + dim_hiddenState, dim_hiddenState)\n",
    "        self.i2a = nn.Linear(dim_catagory + dim_inputChar + dim_hiddenState, dim_output)\n",
    "        self.r2o = nn.Linear(dim_output + dim_hiddenState, dim_output)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, catagory_tensor, input_tensor, hidden_tensor):\n",
    "        combined = torch.cat([ catagory_tensor, input_tensor, hidden_tensor], 1)\n",
    "        hiddenState = self.i2h(combined)\n",
    "        abstraction = self.i2a(combined)\n",
    "        rep4clf = torch.cat([hiddenState, abstraction], 1)\n",
    "        scores = self.r2o(rep4clf)\n",
    "        logProbs = self.softmax(self.dropout(scores))\n",
    "        return logProbs, hiddenState\n",
    "    \n",
    "    def init_hidden_state(self):\n",
    "        return Variable(torch.zeros(1, self.hiddenStateDim)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    hidden = rnn.init_hidden_state()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size()[0]):\n",
    "        output, hidden = rnn(category_tensor.cuda(), input_line_tensor[i].cuda(), hidden.cuda())\n",
    "        loss += criterion(output, target_line_tensor[i].cuda())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.data[0] / input_line_tensor.size()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 38s (5000 5%) 2.7450\n",
      "1m 16s (10000 10%) 3.2310\n",
      "1m 55s (15000 15%) 2.4350\n",
      "2m 34s (20000 20%) 2.4102\n",
      "3m 13s (25000 25%) 3.3988\n",
      "3m 53s (30000 30%) 2.0428\n",
      "4m 32s (35000 35%) 2.6142\n",
      "5m 14s (40000 40%) 2.4453\n",
      "5m 57s (45000 45%) 1.9459\n",
      "6m 43s (50000 50%) 2.4700\n",
      "7m 32s (55000 55%) 2.8779\n",
      "8m 19s (60000 60%) 1.7231\n",
      "9m 10s (65000 65%) 2.7455\n",
      "9m 51s (70000 70%) 1.8689\n",
      "10m 44s (75000 75%) 3.1268\n",
      "11m 41s (80000 80%) 2.6730\n",
      "12m 47s (85000 85%) 2.9261\n",
      "14m 45s (90000 90%) 2.3822\n",
      "49m 31s (95000 95%) 1.7886\n",
      "53m 15s (100000 100%) 3.1828\n"
     ]
    }
   ],
   "source": [
    "rnn = GenRNN(n_letters, 128, n_letters)\n",
    "rnn.cuda()\n",
    "\n",
    "n_epochs = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every epochs\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    output, loss = train(*randomTrainingSet())\n",
    "    total_loss += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), epoch, epoch / n_epochs * 100, loss))\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"name_gen.pkl\", \"bw\")\n",
    "torch.save(rnn.state_dict(), f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
